{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9caa00b4",
   "metadata": {},
   "source": [
    "# Classification of Sugarcane Diseases based on Images\n",
    "\n",
    "## Initial Setup\n",
    "\n",
    "Examining the train data shows that there are six (6) classes in total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd64df45",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"Banded_Chlorosis\",\n",
    "    \"Brown_Rust\",\n",
    "    \"Brown_Spot\",\n",
    "    \"Viral\",\n",
    "    \"Yellow_Leaf\",\n",
    "    \"Healthy\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5418fd",
   "metadata": {},
   "source": [
    "To make it easier to handle the image data, a Python class called `Classification` is defined and it will use the OpenCV library.\n",
    "\n",
    "This class will contain the method `load_images` that can be used to load the images, as well as the method `resize_images` for resizing all the images.\n",
    "\n",
    "Property methods `image_count` and `image_dimensions` also allow us to analyze the loaded images and determine if further preprocessing is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fdc1e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Classification:\n",
    "    name: str\n",
    "    images: list[np.ndarray]\n",
    "\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        self.images = list()\n",
    "\n",
    "    @property\n",
    "    def image_count(self) -> int:\n",
    "        return len(self.images)\n",
    "\n",
    "    @property\n",
    "    def image_dimensions(self) -> dict[tuple[int, int, int], int]:\n",
    "        dims = {}\n",
    "        for img in self.images:\n",
    "            if dims.get(img.shape) is None:\n",
    "                dims[img.shape] = 1\n",
    "                continue\n",
    "            dims[img.shape] += 1\n",
    "        return dims\n",
    "\n",
    "    @property\n",
    "    def image_dimensions_distribution(self) -> dict[tuple[int, int, int], int]:\n",
    "        distrib = {}\n",
    "        for key, value in self.image_dimensions.items():\n",
    "            distrib[key] = value / self.image_count\n",
    "        return distrib\n",
    "\n",
    "    def load_images(self, top_folder: str = \"train\") -> None:\n",
    "        \"\"\"\n",
    "        Empties self.images  then loads images using opencv imread\n",
    "\n",
    "        Returns the length of image_array\n",
    "\n",
    "        Raises exception upon error\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.images = list()\n",
    "            path = Path(f\"{top_folder}/{self.name}\")\n",
    "            image_paths = [img_path for img_path in path.iterdir() if img_path.is_file()]\n",
    "            for path in image_paths:\n",
    "                self.images.append(cv2.imread(str(path)))\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def square_images(self, image_size: int = 512, with_padding: bool = True) -> None:\n",
    "        \"\"\"\n",
    "        Resizes all images in self.image_array to the specified image size.\n",
    "\n",
    "        In the event that the source image is not a square and with_padding is True,\n",
    "        padding will be added to the smaller side to ensure aspect ratio of 1.0.\n",
    "\n",
    "        Returns None\n",
    "        \"\"\"\n",
    "        for index, item in enumerate(self.images):\n",
    "            height, width, _ = self.images[index].shape\n",
    "            aspect_ratio = height / width\n",
    "\n",
    "            if not with_padding or aspect_ratio == 1:\n",
    "                self.images[index] = cv2.resize(item, (image_size, image_size))\n",
    "                continue\n",
    "\n",
    "            padding_color = (0, 0, 0)\n",
    "            if aspect_ratio > 1:\n",
    "                width_padding = (height - width) // 2\n",
    "                image = cv2.copyMakeBorder(\n",
    "                    item,\n",
    "                    0,\n",
    "                    0,\n",
    "                    width_padding,\n",
    "                    width_padding,\n",
    "                    cv2.BORDER_CONSTANT,\n",
    "                    value=padding_color,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                height_padding = (width - height) // 2\n",
    "                image = cv2.copyMakeBorder(\n",
    "                    item,\n",
    "                    height_padding,\n",
    "                    height_padding,\n",
    "                    0,\n",
    "                    0,\n",
    "                    cv2.BORDER_CONSTANT,\n",
    "                    value=padding_color,\n",
    "                )\n",
    "\n",
    "            self.images[index] = cv2.resize(image, (image_size, image_size))\n",
    "\n",
    "    def normalize_images(self) -> None:\n",
    "        \"\"\"\n",
    "        Normalizes the values to be from 0 to 1 instead of 0 to 255.\n",
    "\n",
    "        Returns None\n",
    "        \"\"\"\n",
    "        for index, item in enumerate(self.images):\n",
    "            self.images[index] = item / 255.0\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.name}\\n image count: {self.image_count}\\n image dimensions: {self.image_dimensions}\\n dimension distribution: {self.image_dimensions_distribution}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6186a70",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "First, create the instances for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bdc5813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = [Classification(_class) for _class in classes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69c2b32",
   "metadata": {},
   "source": [
    "Then, for each instance, let us load the images under the path `./train/<class_name>`.\n",
    "\n",
    "We will also display the number of images as well as the dimensions of all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0845df61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banded_Chlorosis\n",
      " image count: 424\n",
      " image dimensions: {(1024, 768, 3): 404, (576, 768, 3): 20}\n",
      " dimension distribution: {(1024, 768, 3): 0.9528301886792453, (576, 768, 3): 0.04716981132075472}\n",
      "Brown_Rust\n",
      " image count: 282\n",
      " image dimensions: {(1024, 768, 3): 280, (576, 768, 3): 2}\n",
      " dimension distribution: {(1024, 768, 3): 0.9929078014184397, (576, 768, 3): 0.0070921985815602835}\n",
      "Brown_Spot\n",
      " image count: 1550\n",
      " image dimensions: {(1024, 768, 3): 1481, (576, 768, 3): 69}\n",
      " dimension distribution: {(1024, 768, 3): 0.9554838709677419, (576, 768, 3): 0.044516129032258066}\n",
      "Viral\n",
      " image count: 597\n",
      " image dimensions: {(1024, 768, 3): 501, (576, 768, 3): 96}\n",
      " dimension distribution: {(1024, 768, 3): 0.8391959798994975, (576, 768, 3): 0.16080402010050251}\n",
      "Yellow_Leaf\n",
      " image count: 1074\n",
      " image dimensions: {(1024, 768, 3): 1005, (576, 768, 3): 69}\n",
      " dimension distribution: {(1024, 768, 3): 0.9357541899441341, (576, 768, 3): 0.06424581005586592}\n",
      "Healthy\n",
      " image count: 387\n",
      " image dimensions: {(1024, 768, 3): 374, (576, 768, 3): 13}\n",
      " dimension distribution: {(1024, 768, 3): 0.9664082687338501, (576, 768, 3): 0.03359173126614987}\n"
     ]
    }
   ],
   "source": [
    "for x in classifications:\n",
    "    x.load_images()\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dfe97b",
   "metadata": {},
   "source": [
    "Two important pieces of information can be gleaned from the output.\n",
    "\n",
    "1. It can be seen that the six (6) different classes have an imbalance in image count.\n",
    "\n",
    "This is a problem because it may introduce excessive bias in our models.\n",
    "To avoid this problem, when training the models, we must use proper sampling techniques to ensure equal class distribution.\n",
    "\n",
    "2. The images are rectangular and the dimensions are not homogenous.\n",
    "\n",
    "Most images have a size of `1024x768` but there are some whose size are `576x768` instead.\n",
    "To ensure that our model will be able to process these images later, we can pad the images to make them a square, and then we resize it.\n",
    "\n",
    "Lastly, let us normalize the data so that the values are from 0 to 1 instead of 0 to 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "16970e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banded_Chlorosis\n",
      " image count: 424\n",
      " image dimensions: {(512, 512, 3): 424}\n",
      " dimension distribution: {(512, 512, 3): 1.0}\n",
      "Brown_Rust\n",
      " image count: 282\n",
      " image dimensions: {(512, 512, 3): 282}\n",
      " dimension distribution: {(512, 512, 3): 1.0}\n",
      "Brown_Spot\n",
      " image count: 1550\n",
      " image dimensions: {(512, 512, 3): 1550}\n",
      " dimension distribution: {(512, 512, 3): 1.0}\n",
      "Viral\n",
      " image count: 597\n",
      " image dimensions: {(512, 512, 3): 597}\n",
      " dimension distribution: {(512, 512, 3): 1.0}\n",
      "Yellow_Leaf\n",
      " image count: 1074\n",
      " image dimensions: {(512, 512, 3): 1074}\n",
      " dimension distribution: {(512, 512, 3): 1.0}\n",
      "Healthy\n",
      " image count: 387\n",
      " image dimensions: {(512, 512, 3): 387}\n",
      " dimension distribution: {(512, 512, 3): 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Resize all images to 512x512\n",
    "for x in classifications:\n",
    "    x.square_images(512, with_padding=True)\n",
    "    x.normalize_images()\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4b4929",
   "metadata": {},
   "source": [
    "## Method 1: Convolution Neural Network (CNN)\n",
    "\n",
    "The first method for solving this classification problem is through the use of CNN.\n",
    "\n",
    "We will be using the Keras and TensorFlow libraries.\n",
    "\n",
    "First, let us setup the environment and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326c5d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import keras\n",
    "\n",
    "# Set Keras backend to use TensorFlow\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "# Define the expected inputs\n",
    "image_inputs = keras.Input(\n",
    "    shape=classifications[0].images[0].shape, dtype=classifications[0].images[0].dtype\n",
    ")\n",
    "\n",
    "# Define model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

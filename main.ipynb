{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9caa00b4",
   "metadata": {},
   "source": [
    "# Classification of Sugarcane Diseases based on Images\n",
    "\n",
    "## Initial Setup\n",
    "\n",
    "Examining the train data shows that there are six (6) classes in total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd64df45",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"Banded_Chlorosis\",\n",
    "    \"Brown_Rust\",\n",
    "    \"Brown_Spot\",\n",
    "    \"Viral\",\n",
    "    \"Yellow_Leaf\",\n",
    "    \"Healthy\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5418fd",
   "metadata": {},
   "source": [
    "To make it easier to handle the image data, a Python class called `Classification` is defined and it will use the OpenCV library.\n",
    "\n",
    "This class will contain the method `load_images` that can be used to load the images, as well as the method `resize_images` for resizing all the images.\n",
    "\n",
    "Property methods `image_count` and `image_dimensions` also allow us to analyze the loaded images and determine if further preprocessing is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdc1e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Classification:\n",
    "    name: str\n",
    "    images: list[np.ndarray]\n",
    "\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        self.images = list()\n",
    "\n",
    "    @property\n",
    "    def image_count(self) -> int:\n",
    "        return len(self.images)\n",
    "\n",
    "    @property\n",
    "    def image_dimensions(self) -> dict[tuple[int, int, int], int]:\n",
    "        dims = {}\n",
    "        for img in self.images:\n",
    "            if dims.get(img.shape) is None:\n",
    "                dims[img.shape] = 1\n",
    "                continue\n",
    "            dims[img.shape] += 1\n",
    "        return dims\n",
    "\n",
    "    @property\n",
    "    def image_dimensions_distribution(self) -> dict[tuple[int, int, int], int]:\n",
    "        distrib = {}\n",
    "        for key, value in self.image_dimensions.items():\n",
    "            distrib[key] = value/self.image_count\n",
    "        return distrib\n",
    "\n",
    "    def load_images(self, top_folder: str = \"train\") -> None:\n",
    "        \"\"\"\n",
    "        Empties self.images  then loads images using opencv imread\n",
    "\n",
    "        Returns the length of image_array\n",
    "\n",
    "        Raises exception upon error\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.images = list()\n",
    "            path = Path(f\"{top_folder}/{self.name}\")\n",
    "            image_paths = [img_path for img_path in path.iterdir() if img_path.is_file()]\n",
    "            for path in image_paths:\n",
    "                self.images.append(cv2.imread(str(path)))\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def resize_images(self, image_size: tuple[int, int]) -> None:\n",
    "        \"\"\"\n",
    "        Resizes all images in self.image_array to the specified image size.\n",
    "\n",
    "        Returns None\n",
    "        \"\"\"\n",
    "        for index in range(len(self.images)):\n",
    "            self.images[index] = cv2.resize(self.images[index], image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6186a70",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "First, create the instances for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdc5813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = [Classification(_class) for _class in classes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69c2b32",
   "metadata": {},
   "source": [
    "Then, for each instance, let us load the images under the path `./train/<class_name>`.\n",
    "\n",
    "We will also display the number of images as well as the dimensions of all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0845df61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banded_Chlorosis\n",
      " image count: 424\n",
      " image dimensions: {(1024, 768, 3): 404, (576, 768, 3): 20}\n",
      " dimension distribution: {(1024, 768, 3): 0.9528301886792453, (576, 768, 3): 0.04716981132075472} \n",
      "Brown_Rust\n",
      " image count: 282\n",
      " image dimensions: {(1024, 768, 3): 280, (576, 768, 3): 2}\n",
      " dimension distribution: {(1024, 768, 3): 0.9929078014184397, (576, 768, 3): 0.0070921985815602835} \n",
      "Brown_Spot\n",
      " image count: 1550\n",
      " image dimensions: {(1024, 768, 3): 1481, (576, 768, 3): 69}\n",
      " dimension distribution: {(1024, 768, 3): 0.9554838709677419, (576, 768, 3): 0.044516129032258066} \n",
      "Viral\n",
      " image count: 597\n",
      " image dimensions: {(1024, 768, 3): 501, (576, 768, 3): 96}\n",
      " dimension distribution: {(1024, 768, 3): 0.8391959798994975, (576, 768, 3): 0.16080402010050251} \n",
      "Yellow_Leaf\n",
      " image count: 1074\n",
      " image dimensions: {(1024, 768, 3): 1005, (576, 768, 3): 69}\n",
      " dimension distribution: {(1024, 768, 3): 0.9357541899441341, (576, 768, 3): 0.06424581005586592} \n",
      "Healthy\n",
      " image count: 387\n",
      " image dimensions: {(1024, 768, 3): 374, (576, 768, 3): 13}\n",
      " dimension distribution: {(1024, 768, 3): 0.9664082687338501, (576, 768, 3): 0.03359173126614987} \n"
     ]
    }
   ],
   "source": [
    "for x in classifications:\n",
    "    x.load_images()\n",
    "    print(f\"{x.name}\\n image count: {x.image_count}\\n image dimensions: {x.image_dimensions}\\n dimension distribution: {x.image_dimensions_distribution} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dfe97b",
   "metadata": {},
   "source": [
    "Two important pieces of information can be gleaned from the output.\n",
    "\n",
    "1. It can be seen that the six (6) different classes have an imbalance in image count.\n",
    "\n",
    "This is a problem because it may introduce excessive bias in our models.\n",
    "To avoid this problem, when training the models, we must use proper sampling techniques to ensure equal class distribution.\n",
    "\n",
    "2. The images are rectangular and the dimensions are not homogenous.\n",
    "\n",
    "Most images have a size of `1024x768` but there are some whose size are `576x768` instead.\n",
    "Looking at the distribution show that they are safe to drop due to the acceptable percentage.\n",
    "The class `Viral` has the highest percentage of `576x768` images at about 16%. \n",
    "However, class `Viral` still would still have more `1024x768` images than class `Brown_Rust` even after dropping all `576x768` images.\n",
    "Therefore, these images can be dropped. \n",
    "The difference in aspect ratios mean that resizing these images to match the majority will introduce distortion that may lead to unintended effects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16970e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banded_Chlorosis\n",
      " image count: 404\n",
      " image dimensions: {(1024, 768, 3): 404}\n",
      "\n",
      "Brown_Rust\n",
      " image count: 280\n",
      " image dimensions: {(1024, 768, 3): 280}\n",
      "\n",
      "Brown_Spot\n",
      " image count: 1481\n",
      " image dimensions: {(1024, 768, 3): 1481}\n",
      "\n",
      "Viral\n",
      " image count: 501\n",
      " image dimensions: {(1024, 768, 3): 501}\n",
      "\n",
      "Yellow_Leaf\n",
      " image count: 1005\n",
      " image dimensions: {(1024, 768, 3): 1005}\n",
      "\n",
      "Healthy\n",
      " image count: 374\n",
      " image dimensions: {(1024, 768, 3): 374}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove all images with dimensions (576, 768, 3)\n",
    "for x in classifications:\n",
    "    x.images = list(filter(lambda img: img.shape != (576, 768, 3), x.images))\n",
    "    print(f\"{x.name}\\n image count: {x.image_count}\\n image dimensions: {x.image_dimensions}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
